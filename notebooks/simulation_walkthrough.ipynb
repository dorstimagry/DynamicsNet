{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural EV Dynamics Simulation Walkthrough\n",
    "\n",
    "This notebook demonstrates end-to-end usage of the transformer-based EV longitudinal controllers:\n",
    "\n",
    "1. Load Stage 1 (forward/inverse) and Stage 2 (feedback) models.\n",
    "2. Generate synthetic speed and grade profiles (or load from disk).\n",
    "3. Run forward-only, inverse-only, and closed-loop simulations with perturbations.\n",
    "4. Visualize the trajectories and error statistics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:00.184716Z",
     "iopub.status.busy": "2025-11-06T14:54:00.184566Z",
     "iopub.status.idle": "2025-11-06T14:54:00.187657Z",
     "shell.execute_reply": "2025-11-06T14:54:00.187483Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().resolve().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:00.197121Z",
     "iopub.status.busy": "2025-11-06T14:54:00.197043Z",
     "iopub.status.idle": "2025-11-06T14:54:00.995106Z",
     "shell.execute_reply": "2025-11-06T14:54:00.994813Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time as pytime\n",
    "\n",
    "from scripts.simulate_profiles import (\n",
    "    PerturbationConfig,\n",
    "    load_models,\n",
    "    simulate_forward,\n",
    "    simulate_inverse,\n",
    "    simulate_closed_loop,\n",
    "    SequenceWindowConfig,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paths and Configuration\n",
    "Fill in the checkpoint paths and simulation hyperparameters. The defaults below assume you ran Stage 1/2 trainings from the earlier walkthrough.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:00.996388Z",
     "iopub.status.busy": "2025-11-06T14:54:00.996266Z",
     "iopub.status.idle": "2025-11-06T14:54:01.015655Z",
     "shell.execute_reply": "2025-11-06T14:54:01.015358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update these paths to match your environment\n",
    "STAGE1_CKPT = Path(\"../checkpoints/stage1/ecentro_ha_03_bs512/stage1.pth\")\n",
    "STAGE2_CKPT = Path(\"../checkpoints/stage2/ecentro_ha_03_bs512/stage2.pth\")\n",
    "DATASET_PATH = Path(\"../data/processed/ECentro/ECENTRO_HA_03/all_trips_data.pt\")\n",
    "\n",
    "HISTORY = 100\n",
    "HORIZON = 100\n",
    "TOTAL_LENGTH = 1200  # total timesteps to simulate for closed-loop mode\n",
    "SAMPLE_TIME = 0.1  # controller timestep in seconds\n",
    "WARMUP_DURATION = 15.0  # seconds for ramp-to-initial-speed warmup\n",
    "\n",
    "# Target speed profile options\n",
    "TARGET_PROFILE_TYPE = \"steps\"  # options: \"sine\", \"steps\"\n",
    "# Sequence of (duration_seconds, speed_mps) applied after the warm-up when TARGET_PROFILE_TYPE == \"steps\"\n",
    "STEP_PROFILE_SEGMENTS = [\n",
    "    (30.0, 1.5),\n",
    "    (30.0, 5.0),\n",
    "    (30.0, 3.0),\n",
    "    (30.0, 7.0),\n",
    "    (10.0, 0.0),\n",
    "]\n",
    "\n",
    "STATE_FEATURES = [\"speed\", \"grade\", \"acceleration\"]\n",
    "\n",
    "window = SequenceWindowConfig(history=HISTORY, horizon=HORIZON)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.016678Z",
     "iopub.status.busy": "2025-11-06T14:54:01.016541Z",
     "iopub.status.idle": "2025-11-06T14:54:01.208147Z",
     "shell.execute_reply": "2025-11-06T14:54:01.207766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/imagry/DynamicsNet/DynamicsNet/scripts/simulate_profiles.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stage1_state = torch.load(stage1, map_location=\"cpu\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ForwardDynamicsModel:\n\tMissing key(s) in state_dict: \"backbone.gru.weight_ih_l0\", \"backbone.gru.weight_hh_l0\", \"backbone.gru.bias_ih_l0\", \"backbone.gru.bias_hh_l0\", \"backbone.gru.weight_ih_l0_reverse\", \"backbone.gru.weight_hh_l0_reverse\", \"backbone.gru.bias_ih_l0_reverse\", \"backbone.gru.bias_hh_l0_reverse\", \"backbone.gru.weight_ih_l1\", \"backbone.gru.weight_hh_l1\", \"backbone.gru.bias_ih_l1\", \"backbone.gru.bias_hh_l1\", \"backbone.gru.weight_ih_l1_reverse\", \"backbone.gru.weight_hh_l1_reverse\", \"backbone.gru.bias_ih_l1_reverse\", \"backbone.gru.bias_hh_l1_reverse\", \"backbone.projection.weight\", \"backbone.projection.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.encoder.layers.0.self_attn.in_proj_weight\", \"backbone.encoder.layers.0.self_attn.in_proj_bias\", \"backbone.encoder.layers.0.self_attn.out_proj.weight\", \"backbone.encoder.layers.0.self_attn.out_proj.bias\", \"backbone.encoder.layers.0.linear1.weight\", \"backbone.encoder.layers.0.linear1.bias\", \"backbone.encoder.layers.0.linear2.weight\", \"backbone.encoder.layers.0.linear2.bias\", \"backbone.encoder.layers.0.norm1.weight\", \"backbone.encoder.layers.0.norm1.bias\", \"backbone.encoder.layers.0.norm2.weight\", \"backbone.encoder.layers.0.norm2.bias\", \"backbone.encoder.layers.1.self_attn.in_proj_weight\", \"backbone.encoder.layers.1.self_attn.in_proj_bias\", \"backbone.encoder.layers.1.self_attn.out_proj.weight\", \"backbone.encoder.layers.1.self_attn.out_proj.bias\", \"backbone.encoder.layers.1.linear1.weight\", \"backbone.encoder.layers.1.linear1.bias\", \"backbone.encoder.layers.1.linear2.weight\", \"backbone.encoder.layers.1.linear2.bias\", \"backbone.encoder.layers.1.norm1.weight\", \"backbone.encoder.layers.1.norm1.bias\", \"backbone.encoder.layers.1.norm2.weight\", \"backbone.encoder.layers.1.norm2.bias\", \"backbone.encoder.layers.2.self_attn.in_proj_weight\", \"backbone.encoder.layers.2.self_attn.in_proj_bias\", \"backbone.encoder.layers.2.self_attn.out_proj.weight\", \"backbone.encoder.layers.2.self_attn.out_proj.bias\", \"backbone.encoder.layers.2.linear1.weight\", \"backbone.encoder.layers.2.linear1.bias\", \"backbone.encoder.layers.2.linear2.weight\", \"backbone.encoder.layers.2.linear2.bias\", \"backbone.encoder.layers.2.norm1.weight\", \"backbone.encoder.layers.2.norm1.bias\", \"backbone.encoder.layers.2.norm2.weight\", \"backbone.encoder.layers.2.norm2.bias\", \"backbone.encoder.layers.3.self_attn.in_proj_weight\", \"backbone.encoder.layers.3.self_attn.in_proj_bias\", \"backbone.encoder.layers.3.self_attn.out_proj.weight\", \"backbone.encoder.layers.3.self_attn.out_proj.bias\", \"backbone.encoder.layers.3.linear1.weight\", \"backbone.encoder.layers.3.linear1.bias\", \"backbone.encoder.layers.3.linear2.weight\", \"backbone.encoder.layers.3.linear2.bias\", \"backbone.encoder.layers.3.norm1.weight\", \"backbone.encoder.layers.3.norm1.bias\", \"backbone.encoder.layers.3.norm2.weight\", \"backbone.encoder.layers.3.norm2.bias\", \"backbone.encoder.norm.weight\", \"backbone.encoder.norm.bias\". \n\tsize mismatch for history_proj.net.0.weight: copying a param with shape torch.Size([256, 4]) from checkpoint, the shape in current model is torch.Size([256, 5]).\n\tsize mismatch for output_head.2.weight: copying a param with shape torch.Size([2, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).\n\tsize mismatch for output_head.2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m forward_model, inverse_model, feedback_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSTAGE1_CKPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSTAGE2_CKPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSTATE_FEATURES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount_params\u001b[39m(model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m/opt/imagry/DynamicsNet/DynamicsNet/scripts/simulate_profiles.py:35\u001b[0m, in \u001b[0;36mload_models\u001b[0;34m(stage1, stage2, state_dim, action_dim, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m feedback \u001b[38;5;241m=\u001b[39m FeedbackResidualModel(FeedbackModelConfig(state_dim, action_dim, cfg))\n\u001b[1;32m     34\u001b[0m stage1_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(stage1, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mforward\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage1_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m inverse\u001b[38;5;241m.\u001b[39mload_state_dict(stage1_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minverse_model\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m stage2_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(stage2, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ForwardDynamicsModel:\n\tMissing key(s) in state_dict: \"backbone.gru.weight_ih_l0\", \"backbone.gru.weight_hh_l0\", \"backbone.gru.bias_ih_l0\", \"backbone.gru.bias_hh_l0\", \"backbone.gru.weight_ih_l0_reverse\", \"backbone.gru.weight_hh_l0_reverse\", \"backbone.gru.bias_ih_l0_reverse\", \"backbone.gru.bias_hh_l0_reverse\", \"backbone.gru.weight_ih_l1\", \"backbone.gru.weight_hh_l1\", \"backbone.gru.bias_ih_l1\", \"backbone.gru.bias_hh_l1\", \"backbone.gru.weight_ih_l1_reverse\", \"backbone.gru.weight_hh_l1_reverse\", \"backbone.gru.bias_ih_l1_reverse\", \"backbone.gru.bias_hh_l1_reverse\", \"backbone.projection.weight\", \"backbone.projection.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.encoder.layers.0.self_attn.in_proj_weight\", \"backbone.encoder.layers.0.self_attn.in_proj_bias\", \"backbone.encoder.layers.0.self_attn.out_proj.weight\", \"backbone.encoder.layers.0.self_attn.out_proj.bias\", \"backbone.encoder.layers.0.linear1.weight\", \"backbone.encoder.layers.0.linear1.bias\", \"backbone.encoder.layers.0.linear2.weight\", \"backbone.encoder.layers.0.linear2.bias\", \"backbone.encoder.layers.0.norm1.weight\", \"backbone.encoder.layers.0.norm1.bias\", \"backbone.encoder.layers.0.norm2.weight\", \"backbone.encoder.layers.0.norm2.bias\", \"backbone.encoder.layers.1.self_attn.in_proj_weight\", \"backbone.encoder.layers.1.self_attn.in_proj_bias\", \"backbone.encoder.layers.1.self_attn.out_proj.weight\", \"backbone.encoder.layers.1.self_attn.out_proj.bias\", \"backbone.encoder.layers.1.linear1.weight\", \"backbone.encoder.layers.1.linear1.bias\", \"backbone.encoder.layers.1.linear2.weight\", \"backbone.encoder.layers.1.linear2.bias\", \"backbone.encoder.layers.1.norm1.weight\", \"backbone.encoder.layers.1.norm1.bias\", \"backbone.encoder.layers.1.norm2.weight\", \"backbone.encoder.layers.1.norm2.bias\", \"backbone.encoder.layers.2.self_attn.in_proj_weight\", \"backbone.encoder.layers.2.self_attn.in_proj_bias\", \"backbone.encoder.layers.2.self_attn.out_proj.weight\", \"backbone.encoder.layers.2.self_attn.out_proj.bias\", \"backbone.encoder.layers.2.linear1.weight\", \"backbone.encoder.layers.2.linear1.bias\", \"backbone.encoder.layers.2.linear2.weight\", \"backbone.encoder.layers.2.linear2.bias\", \"backbone.encoder.layers.2.norm1.weight\", \"backbone.encoder.layers.2.norm1.bias\", \"backbone.encoder.layers.2.norm2.weight\", \"backbone.encoder.layers.2.norm2.bias\", \"backbone.encoder.layers.3.self_attn.in_proj_weight\", \"backbone.encoder.layers.3.self_attn.in_proj_bias\", \"backbone.encoder.layers.3.self_attn.out_proj.weight\", \"backbone.encoder.layers.3.self_attn.out_proj.bias\", \"backbone.encoder.layers.3.linear1.weight\", \"backbone.encoder.layers.3.linear1.bias\", \"backbone.encoder.layers.3.linear2.weight\", \"backbone.encoder.layers.3.linear2.bias\", \"backbone.encoder.layers.3.norm1.weight\", \"backbone.encoder.layers.3.norm1.bias\", \"backbone.encoder.layers.3.norm2.weight\", \"backbone.encoder.layers.3.norm2.bias\", \"backbone.encoder.norm.weight\", \"backbone.encoder.norm.bias\". \n\tsize mismatch for history_proj.net.0.weight: copying a param with shape torch.Size([256, 4]) from checkpoint, the shape in current model is torch.Size([256, 5]).\n\tsize mismatch for output_head.2.weight: copying a param with shape torch.Size([2, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).\n\tsize mismatch for output_head.2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3])."
     ]
    }
   ],
   "source": [
    "forward_model, inverse_model, feedback_model = load_models(\n",
    "    STAGE1_CKPT,\n",
    "    STAGE2_CKPT,\n",
    "    state_dim=len(STATE_FEATURES),\n",
    "    action_dim=2,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "def count_params(model: torch.nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"Models loaded on\", device)\n",
    "print(\n",
    "    f\"Forward params: {count_params(forward_model):,}\",\n",
    "    f\"Inverse params: {count_params(inverse_model):,}\",\n",
    "    f\"Feedback params: {count_params(feedback_model):,}\",\n",
    "    sep=\"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.231735Z",
     "iopub.status.busy": "2025-11-06T14:54:01.231575Z",
     "iopub.status.idle": "2025-11-06T14:54:01.233517Z",
     "shell.execute_reply": "2025-11-06T14:54:01.233310Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = None\n",
    "auto_mapper = None\n",
    "print(\"Autoencoder warm-start disabled; using synthetic ramp warmup instead.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Profiles\n",
    "We will synthesise target speed and grade profiles. You can swap these with `np.load` calls if you have recorded trajectories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.234289Z",
     "iopub.status.busy": "2025-11-06T14:54:01.234181Z",
     "iopub.status.idle": "2025-11-06T14:54:01.238206Z",
     "shell.execute_reply": "2025-11-06T14:54:01.238016Z"
    }
   },
   "outputs": [],
   "source": [
    "time = np.arange(TOTAL_LENGTH)\n",
    "\n",
    "INITIAL_TARGET_SPEED = 1.5 # m/s\n",
    "\n",
    "WARMUP_GRADIENT = 1.0  # m/s^2\n",
    "\n",
    "\n",
    "def build_linear_warmup_schedule(gradient: float,\n",
    "                                 target_speed: float = INITIAL_TARGET_SPEED,\n",
    "                                 dt: float = SAMPLE_TIME) -> np.ndarray:\n",
    "    gradient = float(max(gradient, 1e-4))\n",
    "    steps = int(np.ceil(target_speed / (gradient * dt)))\n",
    "    if steps < 1:\n",
    "        steps = 1\n",
    "    speeds = gradient * dt * np.arange(1, steps + 1, dtype=np.float32)\n",
    "    return np.clip(speeds, 0.0, target_speed)\n",
    "\n",
    "\n",
    "def build_target_speed_profile(\n",
    "    warmup_schedule: np.ndarray,\n",
    "    profile_type: str = \"sine\",\n",
    ") -> np.ndarray:\n",
    "    profile = np.ones_like(time, dtype=np.float32) * INITIAL_TARGET_SPEED\n",
    "    warmup_steps = int(np.round(warmup_schedule.size))\n",
    "    after_warmup_steps = warmup_steps\n",
    "    remaining_steps = profile.size - after_warmup_steps\n",
    "    if remaining_steps > 0:\n",
    "        if profile_type == \"sine\":\n",
    "            phase = np.arange(remaining_steps)\n",
    "            profile[after_warmup_steps:] = INITIAL_TARGET_SPEED + 1.5 * np.sin(phase / 60.0)\n",
    "        elif profile_type == \"steps\":\n",
    "            idx = after_warmup_steps\n",
    "            segments = STEP_PROFILE_SEGMENTS or [(remaining_steps * SAMPLE_TIME, float(INITIAL_TARGET_SPEED))]\n",
    "            last_speed = float(INITIAL_TARGET_SPEED)\n",
    "            for duration, speed in segments:\n",
    "                steps = int(np.round(duration / SAMPLE_TIME))\n",
    "                if steps <= 0:\n",
    "                    continue\n",
    "                end = min(idx + steps, profile.size)\n",
    "                profile[idx:end] = float(speed)\n",
    "                last_speed = float(speed)\n",
    "                idx = end\n",
    "                if idx >= profile.size:\n",
    "                    break\n",
    "            if idx < profile.size:\n",
    "                profile[idx:] = last_speed\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown target profile type: {profile_type}\")\n",
    "    return profile\n",
    "\n",
    "\n",
    "DEFAULT_WARMUP_SCHEDULE = build_linear_warmup_schedule(WARMUP_GRADIENT)\n",
    "WARMUP_DURATION = DEFAULT_WARMUP_SCHEDULE.size * SAMPLE_TIME\n",
    "\n",
    "TARGET_SPEED = build_target_speed_profile(DEFAULT_WARMUP_SCHEDULE, TARGET_PROFILE_TYPE)\n",
    "GRADE_PROFILE = np.zeros_like(time, dtype=np.float32)\n",
    "\n",
    "initial_speed = np.zeros(HISTORY, dtype=np.float32)\n",
    "initial_grade_profile = np.zeros(HISTORY, dtype=np.float32)\n",
    "initial_actions = np.zeros((HISTORY, 2), dtype=np.float32)\n",
    "\n",
    "print(\n",
    "    \"Warm-start summary → speed=\",\n",
    "    float(initial_speed[-1]),\n",
    "    \"warmup gradient=\",\n",
    "    WARMUP_GRADIENT,\n",
    "    \"warmup duration [s]=\",\n",
    "    DEFAULT_WARMUP_SCHEDULE.size * SAMPLE_TIME,\n",
    "    \"first target speed=\",\n",
    "    float(TARGET_SPEED[0]),\n",
    "    \"grade=\",\n",
    "    float(initial_grade_profile[-1]),\n",
    "    \"actions(throttle, brake)=\",\n",
    "    tuple(initial_actions[-1]),\n",
    ")\n",
    "print(\"Target profile type=\", TARGET_PROFILE_TYPE)\n",
    "if TARGET_PROFILE_TYPE == \"steps\":\n",
    "    total_segment_duration = sum(float(seg[0]) for seg in STEP_PROFILE_SEGMENTS)\n",
    "    print(\"Step segments (duration [s], speed [m/s]):\", STEP_PROFILE_SEGMENTS)\n",
    "    print(\"Step profile total duration [s]=\", total_segment_duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.238917Z",
     "iopub.status.busy": "2025-11-06T14:54:01.238790Z",
     "iopub.status.idle": "2025-11-06T14:54:01.318235Z",
     "shell.execute_reply": "2025-11-06T14:54:01.317941Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "t_profile = np.arange(1, DEFAULT_WARMUP_SCHEDULE.size + 1) * SAMPLE_TIME\n",
    "ax.plot(t_profile, DEFAULT_WARMUP_SCHEDULE, label=f\"Warm-up (gradient {WARMUP_GRADIENT:.1f} m/s^2)\")\n",
    "ax.set_xlabel(\"Warm-up time [s]\")\n",
    "ax.set_ylabel(\"Target speed [m/s]\")\n",
    "ax.set_title(\"Warm-up Target Speed Profile\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Forward Simulation\n",
    "Given a user-defined actuation horizon, predict the vehicle's future speed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward vs Feedback (Noiseless Simulation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.319292Z",
     "iopub.status.busy": "2025-11-06T14:54:01.319176Z",
     "iopub.status.idle": "2025-11-06T14:54:01.409602Z",
     "shell.execute_reply": "2025-11-06T14:54:01.409304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example actuation sequence: moderate throttle, no brake\n",
    "actuation_horizon = np.zeros((HORIZON, 2), dtype=np.float32)\n",
    "actuation_horizon[:, 0] = 40  # 40% throttle equivalent\n",
    "\n",
    "forward_preds = simulate_forward(\n",
    "    forward_model,\n",
    "    initial_speed,\n",
    "    initial_actions,\n",
    "    actuation_horizon,\n",
    "    GRADE_PROFILE[:HISTORY + HORIZON],\n",
    "    window,\n",
    "    STATE_FEATURES,\n",
    "    device,\n",
    ")\n",
    "print(\"Forward-predicted speeds (first 10):\", forward_preds[:10, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inverse Simulation\n",
    "Given a target speed horizon, compute the required actuation plan (feedforward controller).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.410547Z",
     "iopub.status.busy": "2025-11-06T14:54:01.410448Z",
     "iopub.status.idle": "2025-11-06T14:54:01.425313Z",
     "shell.execute_reply": "2025-11-06T14:54:01.425038Z"
    }
   },
   "outputs": [],
   "source": [
    "target_window = TARGET_SPEED[HISTORY : HISTORY + HORIZON]\n",
    "\n",
    "inverse_actions = simulate_inverse(\n",
    "    inverse_model,\n",
    "    initial_speed,\n",
    "    initial_actions,\n",
    "    target_window,\n",
    "    GRADE_PROFILE[:HISTORY + HORIZON],\n",
    "    window,\n",
    "    STATE_FEATURES,\n",
    "    device,\n",
    ")\n",
    "print(\"Inverse-predicted throttle/brake (first 10 rows):\\n\", inverse_actions[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Closed-loop Simulation\n",
    "At each time step:\n",
    "1. Feed the latest noisy measurements to the inverse (and optional feedback) model to obtain actuations.\n",
    "2. Apply optional actuation noise.\n",
    "3. Propagate the true state with the forward model (vehicle response).\n",
    "4. Update history windows and continue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:01.426303Z",
     "iopub.status.busy": "2025-11-06T14:54:01.426220Z",
     "iopub.status.idle": "2025-11-06T14:54:27.616621Z",
     "shell.execute_reply": "2025-11-06T14:54:27.616326Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_closed_loop_case(\n",
    "    feedback_module,\n",
    "    perturb,\n",
    "    warmup_schedule: Optional[np.ndarray] = None,\n",
    "):\n",
    "    schedule = (\n",
    "        np.asarray(warmup_schedule, dtype=np.float32)\n",
    "        if warmup_schedule is not None\n",
    "        else DEFAULT_WARMUP_SCHEDULE\n",
    "    )\n",
    "    warmup_seconds = schedule.size * SAMPLE_TIME\n",
    "    return simulate_closed_loop(\n",
    "        forward_model,\n",
    "        inverse_model,\n",
    "        feedback_module,\n",
    "        initial_speed,\n",
    "        initial_actions,\n",
    "        TARGET_SPEED.copy(),\n",
    "        GRADE_PROFILE.copy(),\n",
    "        window,\n",
    "        STATE_FEATURES,\n",
    "        device,\n",
    "        perturb=perturb,\n",
    "        warmup_seconds=warmup_seconds,\n",
    "        time_step=SAMPLE_TIME,\n",
    "        warmup_speed_schedule=schedule,\n",
    "    )\n",
    "\n",
    "results_clean_ff = run_closed_loop_case(None, None)\n",
    "results_clean_fb = run_closed_loop_case(feedback_model, None)\n",
    "\n",
    "print(\n",
    "    \"Feedforward-only speed (first 10):\",\n",
    "    results_clean_ff[\"simulated_speed\"][:10],\n",
    ")\n",
    "print(\n",
    "    \"With feedback speed (first 10):\",\n",
    "    results_clean_fb[\"simulated_speed\"][:10],\n",
    ")\n",
    "print(\"Warmup duration [s] =\", WARMUP_DURATION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:27.617532Z",
     "iopub.status.busy": "2025-11-06T14:54:27.617448Z",
     "iopub.status.idle": "2025-11-06T14:54:27.888929Z",
     "shell.execute_reply": "2025-11-06T14:54:27.888683Z"
    }
   },
   "outputs": [],
   "source": [
    "warmup_ff = results_clean_ff.get(\"warmup\", {})\n",
    "warmup_fb = results_clean_fb.get(\"warmup\", {})\n",
    "\n",
    "if warmup_ff and warmup_fb:\n",
    "    t_ff = np.arange(warmup_ff[\"speed\"].size) * SAMPLE_TIME\n",
    "    t_fb = np.arange(warmup_fb[\"speed\"].size) * SAMPLE_TIME\n",
    "\n",
    "    fig_speed, axes_speed = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    axes_speed[0].plot(t_fb, warmup_fb[\"speed\"], label=\"With feedback\")\n",
    "    axes_speed[0].plot(t_fb, warmup_fb[\"target_speed\"], linestyle=\"--\", label=\"Target\")\n",
    "    axes_speed[0].set_title(\"Warm-up Speed (Feedback Enabled)\")\n",
    "    axes_speed[0].set_ylabel(\"Speed [m/s]\")\n",
    "    axes_speed[0].grid(True, alpha=0.3)\n",
    "    axes_speed[0].legend(loc=\"lower right\")\n",
    "\n",
    "    axes_speed[1].plot(t_ff, warmup_ff[\"speed\"], label=\"Feedforward only\")\n",
    "    axes_speed[1].plot(t_ff, warmup_ff[\"target_speed\"], linestyle=\"--\", label=\"Target\")\n",
    "    axes_speed[1].set_title(\"Warm-up Speed (Feedforward Only)\")\n",
    "    axes_speed[1].set_xlabel(\"Time [s]\")\n",
    "    axes_speed[1].set_ylabel(\"Speed [m/s]\")\n",
    "    axes_speed[1].grid(True, alpha=0.3)\n",
    "    axes_speed[1].legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig_act, axes_act = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    axes_act[0].plot(t_fb, warmup_fb[\"actions\"][:, 0], label=\"Throttle\")\n",
    "    axes_act[0].set_title(\"Warm-up Throttle (Feedback Enabled)\")\n",
    "    axes_act[0].set_ylabel(\"Throttle [%]\")\n",
    "    axes_act[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes_act[1].plot(t_ff, warmup_ff[\"actions\"][:, 0], label=\"Throttle\", color=\"tab:orange\")\n",
    "    axes_act[1].set_title(\"Warm-up Throttle (Feedforward Only)\")\n",
    "    axes_act[1].set_xlabel(\"Time [s]\")\n",
    "    axes_act[1].set_ylabel(\"Throttle [%]\")\n",
    "    axes_act[1].grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warm-up data unavailable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:27.889917Z",
     "iopub.status.busy": "2025-11-06T14:54:27.889826Z",
     "iopub.status.idle": "2025-11-06T14:54:27.891877Z",
     "shell.execute_reply": "2025-11-06T14:54:27.891700Z"
    }
   },
   "outputs": [],
   "source": [
    "warmup_clean = results_clean_fb.get(\"warmup\", {})\n",
    "warmup_speed = warmup_clean.get(\"speed\", np.array([]))\n",
    "warmup_target_speed = warmup_clean.get(\"target_speed\", np.array([]))\n",
    "warmup_grade = warmup_clean.get(\"grade\", np.array([]))\n",
    "warmup_actions = warmup_clean.get(\"actions\", np.zeros((0, 2), dtype=np.float32))\n",
    "final_history_speed = results_clean_fb.get(\"final_history_speed\", initial_speed)\n",
    "final_history_actions = results_clean_fb.get(\"final_history_actions\", initial_actions)\n",
    "final_history_grade = results_clean_fb.get(\"final_history_grade\", np.zeros_like(initial_speed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:27.892514Z",
     "iopub.status.busy": "2025-11-06T14:54:27.892441Z",
     "iopub.status.idle": "2025-11-06T14:54:27.893944Z",
     "shell.execute_reply": "2025-11-06T14:54:27.893770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the placeholder history with the post-warmup history for downstream cells\n",
    "if final_history_speed.size:\n",
    "    initial_speed = final_history_speed.astype(np.float32)\n",
    "if final_history_actions.size:\n",
    "    initial_actions = final_history_actions.astype(np.float32)\n",
    "if final_history_grade.size:\n",
    "    initial_grade_profile = final_history_grade.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up Ramp Diagnostics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:27.894602Z",
     "iopub.status.busy": "2025-11-06T14:54:27.894486Z",
     "iopub.status.idle": "2025-11-06T14:54:28.058350Z",
     "shell.execute_reply": "2025-11-06T14:54:28.057999Z"
    }
   },
   "outputs": [],
   "source": [
    "if warmup_speed.size:\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "    t_warmup = np.arange(warmup_speed.size) * SAMPLE_TIME\n",
    "\n",
    "    ax[0].plot(t_warmup, warmup_target_speed, label=\"Target\", linestyle=\"--\")\n",
    "    ax[0].plot(t_warmup, warmup_speed, label=\"Vehicle speed\")\n",
    "    ax[0].set_ylabel(\"Speed [m/s]\")\n",
    "    ax[0].set_title(\"Warm-up Speed Tracking\")\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "    ax[1].plot(t_warmup, np.degrees(warmup_grade), label=\"Grade (target)\", color=\"tab:brown\")\n",
    "    ax[1].set_ylabel(\"Grade [deg]\")\n",
    "    ax[1].set_title(\"Warm-up Grade Target\")\n",
    "    ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "    ax[2].plot(t_warmup, warmup_actions[:, 0], label=\"Throttle\", color=\"tab:orange\")\n",
    "    ax[2].plot(t_warmup, warmup_actions[:, 1], label=\"Brake\", color=\"tab:red\")\n",
    "    ax[2].set_ylabel(\"Actuation [%]\")\n",
    "    ax[2].set_xlabel(\"Warm-up time [s]\")\n",
    "    ax[2].set_title(\"Warm-up Actuation Commands\")\n",
    "    ax[2].grid(True, alpha=0.3)\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warm-up trace unavailable (no ramp executed).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Closed-loop Results (Clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:28.059325Z",
     "iopub.status.busy": "2025-11-06T14:54:28.059238Z",
     "iopub.status.idle": "2025-11-06T14:54:28.311134Z",
     "shell.execute_reply": "2025-11-06T14:54:28.310857Z"
    }
   },
   "outputs": [],
   "source": [
    "sim_speed_ff = results_clean_ff[\"simulated_speed\"]\n",
    "sim_speed_fb = results_clean_fb[\"simulated_speed\"]\n",
    "actuations_ff = results_clean_ff[\"applied_actions\"]\n",
    "actuations_fb = results_clean_fb[\"applied_actions\"]\n",
    "feedforward_ff = results_clean_ff.get(\"feedforward_actions\")\n",
    "feedforward_fb = results_clean_fb.get(\"feedforward_actions\")\n",
    "feedback_fb = results_clean_fb.get(\"feedback_actions\")\n",
    "time_closed = np.arange(sim_speed_fb.shape[0]) * SAMPLE_TIME\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "ax[0].plot(time_closed, TARGET_SPEED[HISTORY:HISTORY + sim_speed_fb.shape[0]], label=\"Target\", linestyle=\"--\")\n",
    "ax[0].plot(time_closed, sim_speed_ff, label=\"Feedforward only\", color=\"tab:orange\", alpha=0.6)\n",
    "ax[0].plot(time_closed, sim_speed_fb, label=\"With feedback\", color=\"tab:blue\")\n",
    "ax[0].set_ylabel(\"Speed [m/s]\")\n",
    "ax[0].set_title(\"Clean Speed Tracking\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "ax[1].plot(time_closed, actuations_ff[:, 0], label=\"Throttle (FF only)\", color=\"tab:orange\", alpha=0.6)\n",
    "ax[1].plot(time_closed, actuations_fb[:, 0], label=\"Throttle (with FB)\", color=\"tab:blue\")\n",
    "if feedforward_fb is not None:\n",
    "    ax[1].plot(time_closed, feedforward_fb[:, 0], label=\"Feedforward\", linestyle=\"--\", color=\"tab:brown\")\n",
    "if feedback_fb is not None:\n",
    "    ax[1].plot(time_closed, feedback_fb[:, 0], label=\"Feedback Δ\", linestyle=\":\", color=\"tab:green\")\n",
    "ax[1].set_ylabel(\"Throttle [%]\")\n",
    "ax[1].set_title(\"Noisy Throttle Commands\")\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "ax[2].plot(time_closed, actuations_ff[:, 1], label=\"Brake (FF only)\", color=\"tab:red\", alpha=0.4)\n",
    "ax[2].plot(time_closed, actuations_fb[:, 1], label=\"Brake (with FB)\", color=\"tab:pink\")\n",
    "if feedforward_fb is not None:\n",
    "    ax[2].plot(time_closed, feedforward_fb[:, 1], label=\"Feedforward\", linestyle=\"--\", color=\"tab:purple\")\n",
    "if feedback_fb is not None:\n",
    "    ax[2].plot(time_closed, feedback_fb[:, 1], label=\"Feedback Δ\", linestyle=\":\", color=\"tab:gray\")\n",
    "ax[2].set_ylabel(\"Brake [%]\")\n",
    "ax[2].set_xlabel(\"Time [s]\")\n",
    "ax[2].set_title(\"Noisy Brake Commands\")\n",
    "ax[2].grid(True, alpha=0.3)\n",
    "ax[2].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-loop Simulation with Measurement/Actuation Noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:28.312332Z",
     "iopub.status.busy": "2025-11-06T14:54:28.312248Z",
     "iopub.status.idle": "2025-11-06T14:54:32.965063Z",
     "shell.execute_reply": "2025-11-06T14:54:32.964796Z"
    }
   },
   "outputs": [],
   "source": [
    "perturb_cfg = PerturbationConfig(\n",
    "    speed_noise_std=0.2,   # m/s measurement noise\n",
    "    speed_delay=1,         # 1-step delay in speed measurement\n",
    "    grade_noise_std=0.002, # radians\n",
    "    actuation_noise_std=0.05,\n",
    ")\n",
    "\n",
    "results_noisy_ff = run_closed_loop_case(None, perturb_cfg, warmup_schedule=DEFAULT_WARMUP_SCHEDULE)\n",
    "results_noisy_fb = run_closed_loop_case(feedback_model, perturb_cfg, warmup_schedule=DEFAULT_WARMUP_SCHEDULE)\n",
    "\n",
    "print(\n",
    "    \"Feedforward-only speed (first 10, noisy):\",\n",
    "    results_noisy_ff[\"simulated_speed\"][:10],\n",
    ")\n",
    "print(\n",
    "    \"With feedback speed (first 10, noisy):\",\n",
    "    results_noisy_fb[\"simulated_speed\"][:10],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Closed-loop Results (Noisy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:32.966063Z",
     "iopub.status.busy": "2025-11-06T14:54:32.965963Z",
     "iopub.status.idle": "2025-11-06T14:54:33.161573Z",
     "shell.execute_reply": "2025-11-06T14:54:33.161352Z"
    }
   },
   "outputs": [],
   "source": [
    "sim_speed_noisy_ff = results_noisy_ff[\"simulated_speed\"]\n",
    "sim_speed_noisy_fb = results_noisy_fb[\"simulated_speed\"]\n",
    "actuations_noisy_ff = results_noisy_ff[\"applied_actions\"]\n",
    "actuations_noisy_fb = results_noisy_fb[\"applied_actions\"]\n",
    "feedforward_noisy_fb = results_noisy_fb.get(\"feedforward_actions\")\n",
    "feedback_noisy_fb = results_noisy_fb.get(\"feedback_actions\")\n",
    "time_noisy = np.arange(sim_speed_noisy_fb.shape[0]) * SAMPLE_TIME\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "ax[0].plot(time_noisy, TARGET_SPEED[HISTORY:HISTORY + sim_speed_noisy_fb.shape[0]], label=\"Target\", linestyle=\"--\")\n",
    "ax[0].plot(time_noisy, sim_speed_noisy_ff, label=\"Feedforward only\", color=\"tab:orange\", alpha=0.6)\n",
    "ax[0].plot(time_noisy, sim_speed_noisy_fb, label=\"With feedback\", color=\"tab:blue\")\n",
    "ax[0].set_ylabel(\"Speed [m/s]\")\n",
    "ax[0].set_title(\"Clean Speed Tracking\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "ax[1].plot(time_noisy, actuations_noisy_ff[:, 0], label=\"Throttle (FF only)\", color=\"tab:orange\", alpha=0.6)\n",
    "ax[1].plot(time_noisy, actuations_noisy_fb[:, 0], label=\"Throttle (with FB)\", color=\"tab:blue\")\n",
    "if feedforward_noisy_fb is not None:\n",
    "    ax[1].plot(time_noisy, feedforward_noisy_fb[:, 0], label=\"Feedforward\", linestyle=\"--\", color=\"tab:brown\")\n",
    "if feedback_noisy_fb is not None:\n",
    "    ax[1].plot(time_noisy, feedback_noisy_fb[:, 0], label=\"Feedback Δ\", linestyle=\":\", color=\"tab:green\")\n",
    "ax[1].set_ylabel(\"Throttle [%]\")\n",
    "ax[1].set_title(\"Noisy Throttle Commands\")\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "ax[2].plot(time_noisy, actuations_noisy_ff[:, 1], label=\"Brake (FF only)\", color=\"tab:red\", alpha=0.4)\n",
    "ax[2].plot(time_noisy, actuations_noisy_fb[:, 1], label=\"Brake (with FB)\", color=\"tab:pink\")\n",
    "if feedforward_noisy_fb is not None:\n",
    "    ax[2].plot(time_noisy, feedforward_noisy_fb[:, 1], label=\"Feedforward\", linestyle=\"--\", color=\"tab:purple\")\n",
    "if feedback_noisy_fb is not None:\n",
    "    ax[2].plot(time_noisy, feedback_noisy_fb[:, 1], label=\"Feedback Δ\", linestyle=\":\", color=\"tab:gray\")\n",
    "ax[2].set_ylabel(\"Brake [%]\")\n",
    "ax[2].set_xlabel(\"Time [s]\")\n",
    "ax[2].set_title(\"Noisy Brake Commands\")\n",
    "ax[2].grid(True, alpha=0.3)\n",
    "ax[2].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Noise-Free vs Perturbed Controllers\n",
    "Run the closed-loop simulation twice to quantify the effect of measurement noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:33.163056Z",
     "iopub.status.busy": "2025-11-06T14:54:33.162972Z",
     "iopub.status.idle": "2025-11-06T14:54:33.165334Z",
     "shell.execute_reply": "2025-11-06T14:54:33.165151Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "def compute_rmse(results):\n",
    "    target = TARGET_SPEED[HISTORY:HISTORY + results[\"simulated_speed\"].shape[0]]\n",
    "    return rmse(target, results[\"simulated_speed\"])\n",
    "\n",
    "print(f\"Clean RMSE (FF only): {compute_rmse(results_clean_ff):.3f} m/s\")\n",
    "print(f\"Clean RMSE (with FB): {compute_rmse(results_clean_fb):.3f} m/s\")\n",
    "print(f\"Noisy RMSE (FF only): {compute_rmse(results_noisy_ff):.3f} m/s\")\n",
    "print(f\"Noisy RMSE (with FB): {compute_rmse(results_noisy_fb):.3f} m/s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward vs Feedback (Clean Simulation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:33.166095Z",
     "iopub.status.busy": "2025-11-06T14:54:33.166019Z",
     "iopub.status.idle": "2025-11-06T14:54:33.282499Z",
     "shell.execute_reply": "2025-11-06T14:54:33.282245Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_feedforward_fb = results_clean_fb.get(\"feedforward_actions\")\n",
    "clean_feedback_fb = results_clean_fb.get(\"feedback_actions\")\n",
    "if clean_feedforward_fb is not None and clean_feedback_fb is not None:\n",
    "    time_clean = np.arange(clean_feedforward_fb.shape[0]) * SAMPLE_TIME\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "    ax[0].plot(time_clean, clean_feedforward_fb[:, 0], label=\"Feedforward\", color=\"tab:brown\", linestyle=\"--\")\n",
    "    ax[0].plot(time_clean, clean_feedback_fb[:, 0], label=\"Feedback Δ\", color=\"tab:green\", linestyle=\":\")\n",
    "    ax[0].plot(time_clean, clean_feedforward_fb[:, 0] + clean_feedback_fb[:, 0], label=\"Final\", color=\"tab:orange\")\n",
    "    ax[0].set_ylabel(\"Throttle [%]\")\n",
    "    ax[0].set_title(\"Clean Throttle Decomposition\")\n",
    "    ax[0].grid(True, alpha=0.3)\n",
    "    ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "    ax[1].plot(time_clean, clean_feedforward_fb[:, 1], label=\"Feedforward\", color=\"tab:pink\", linestyle=\"--\")\n",
    "    ax[1].plot(time_clean, clean_feedback_fb[:, 1], label=\"Feedback Δ\", color=\"tab:purple\", linestyle=\":\")\n",
    "    ax[1].plot(time_clean, clean_feedforward_fb[:, 1] + clean_feedback_fb[:, 1], label=\"Final\", color=\"tab:red\")\n",
    "    ax[1].set_ylabel(\"Brake [%]\")\n",
    "    ax[1].set_xlabel(\"Time [s]\")\n",
    "    ax[1].set_title(\"Clean Brake Decomposition\")\n",
    "    ax[1].grid(True, alpha=0.3)\n",
    "    ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Feedforward/feedback signals not available in clean results.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:33.283406Z",
     "iopub.status.busy": "2025-11-06T14:54:33.283325Z",
     "iopub.status.idle": "2025-11-06T14:54:33.357815Z",
     "shell.execute_reply": "2025-11-06T14:54:33.357564Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.plot(results_clean_ff[\"simulated_speed\"], label=\"Clean FF\", alpha=0.6)\n",
    "ax.plot(results_clean_fb[\"simulated_speed\"], label=\"Clean FB\", alpha=0.9)\n",
    "ax.plot(results_noisy_ff[\"simulated_speed\"], label=\"Noisy FF\", alpha=0.6)\n",
    "ax.plot(results_noisy_fb[\"simulated_speed\"], label=\"Noisy FB\", alpha=0.9)\n",
    "ax.plot(\n",
    "    TARGET_SPEED[HISTORY:HISTORY + len(results_clean_fb[\"simulated_speed\"])],\n",
    "    label=\"Target\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.set_title(\"Speed Tracking: Feedforward vs Feedback\")\n",
    "ax.set_ylabel(\"Speed [m/s]\")\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.legend(ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Performance\n",
    "We benchmark single forward passes for the trained models to understand realtime feasibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T14:54:33.358702Z",
     "iopub.status.busy": "2025-11-06T14:54:33.358620Z",
     "iopub.status.idle": "2025-11-06T14:56:15.910994Z",
     "shell.execute_reply": "2025-11-06T14:56:15.910731Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.datasets import EVSequenceDataset, SequenceWindowConfig as DSWindowConfig\n",
    "\n",
    "timing_dataset = EVSequenceDataset(\n",
    "    DATASET_PATH,\n",
    "    window=DSWindowConfig(history=HISTORY, horizon=HORIZON),\n",
    ")\n",
    "sample = timing_dataset[0]\n",
    "\n",
    "history_states_t = sample[\"history_states\"].unsqueeze(0).to(device)\n",
    "history_actions_t = sample[\"history_actions\"].unsqueeze(0).to(device)\n",
    "future_states_t = sample[\"future_states\"].unsqueeze(0).to(device)\n",
    "future_actions_t = sample[\"future_actions\"].unsqueeze(0).to(device)\n",
    "history_residual_t = torch.zeros_like(history_actions_t)\n",
    "\n",
    "forward_model.eval()\n",
    "inverse_model.eval()\n",
    "feedback_model.eval()\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def measure_latency(fn, warmup: int = 10, iters: int = 100) -> float:\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    start = pytime.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    end = pytime.perf_counter()\n",
    "    return (end - start) / iters\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inverse():\n",
    "    return inverse_model(history_states_t, history_actions_t, future_states_t)\n",
    "\n",
    "\n",
    "def run_forward(actions: torch.Tensor):\n",
    "    with torch.no_grad():\n",
    "        return forward_model(history_states_t, history_actions_t, actions)\n",
    "\n",
    "\n",
    "feedforward_baseline = run_inverse()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_feedback():\n",
    "    return feedback_model(\n",
    "        history_states_t,\n",
    "        history_actions_t,\n",
    "        future_states_t,\n",
    "        feedforward_baseline,\n",
    "        history_residual_actions=history_residual_t,\n",
    "    )\n",
    "\n",
    "lat_inverse = measure_latency(run_inverse)\n",
    "lat_feedback = measure_latency(run_feedback)\n",
    "lat_forward_gt = measure_latency(lambda: run_forward(future_actions_t))\n",
    "lat_forward_ff = measure_latency(lambda: run_forward(feedforward_baseline))\n",
    "\n",
    "print(\n",
    "    f\"Inverse model latency: {lat_inverse * 1e3:.3f} ms\",\n",
    "    f\"Feedback model latency: {lat_feedback * 1e3:.3f} ms\",\n",
    "    f\"Forward model latency (GT actuations): {lat_forward_gt * 1e3:.3f} ms\",\n",
    "    f\"Forward model latency (FF actuations): {lat_forward_ff * 1e3:.3f} ms\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "- Swap the synthetic profiles with recorded data (`np.load`).\n",
    "- Tune `PerturbationConfig` to emulate additional disturbances (e.g., wheel slip).\n",
    "- Integrate the loop into larger planning stacks for MPC benchmarking.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
